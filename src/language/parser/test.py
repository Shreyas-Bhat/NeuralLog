"""
Testing
"""

import logging
import os
import sys

def configure_log():
    """
    Configures the log handler, message format and log level
    """
    level = logging.DEBUG
    h1 = logging.StreamHandler(sys.stdout)
    h1.setLevel(level)
    h1.addFilter(lambda record: record.levelno <= level)
    h2 = logging.StreamHandler(sys.stderr)
    h2.setLevel(logging.WARNING)
    handlers = [h1, h2]
    # handlers = [h1]
    logging.basicConfig(
        format='%(message)s',
        level=level,
        handlers=handlers
    )

configure_log()
logger = logging.getLogger()


from antlr4 import *

from src.knowledge.program import NeuralLogProgram, print_neural_log_program
from src.language.language import Predicate, Constant
from src.language.parser.autogenerated.NeuralLogLexer import NeuralLogLexer
from src.language.parser.autogenerated.NeuralLogParser import NeuralLogParser
from src.language.parser.neural_log_listener import NeuralLogTransverse
from src.network.network import NeuralLogNetwork, NeuralLogDataset
import numpy as np
import tensorflow as tf


def get_clauses(filepath):
    lexer = NeuralLogLexer(FileStream(filepath, "utf-8"))
    stream = CommonTokenStream(lexer)
    parser = NeuralLogParser(stream)
    abstract_syntax_tree = parser.program()
    transverse = NeuralLogTransverse()
    clauses = transverse(abstract_syntax_tree)
    return clauses


def main(argv):
    """
    Main function.

    :param argv: the arguments
    :type argv: list[str]
    """
    resources = "/Users/Victor/PycharmProjects/NeuralLog/test/resources"
    program = get_clauses(os.path.join(resources, "kinship.pl"))
    examples_1 = get_clauses(os.path.join(resources, "kinship_examples1.pl"))
    examples_2 = get_clauses(os.path.join(resources, "kinship_examples2.pl"))

    neural_program = NeuralLogProgram() # type: NeuralLogProgram
    neural_program.add_clauses(program)
    neural_program.add_clauses(examples_1, example_set="examples_1")
    neural_program.add_clauses(examples_2, example_set="examples_2")
    neural_program.build_program()

    print("\n\nNeuralLog Program:\n")
    print("Facts: ({})".format(
        sum(map(lambda x: len(x), neural_program.facts_by_predicate.values()))
    ))
    for predicate in sorted(neural_program.facts_by_predicate.keys(),
                            key=lambda x: x.__str__()):
        for fact in neural_program.facts_by_predicate[predicate].values():
            print(fact)

    print("\n\nClauses: ({})".format(
        sum(map(lambda x: len(x), neural_program.clauses_by_predicate.values()))
    ))
    targets = dict()
    for predicate in sorted(neural_program.clauses_by_predicate.keys(),
                            key=lambda x: x.__str__()):
        for clause in neural_program.clauses_by_predicate[predicate]:
            targets[clause.head.predicate.name] = clause
            print(clause)

    print("\n\nPredicates: ({})".format(len(neural_program.predicates)))
    for predicate in sorted(neural_program.predicates.keys(),
                            key=lambda x: x.__str__()):
        if predicate in neural_program.logic_predicates:
            print("LOGIC   ", predicate, sep="\t")
        else:
            print("FUNCTION", predicate, sep="\t")

    print("\n\nTrainables: ({})".format(
        len(neural_program.trainable_predicates)))
    for predicate in sorted(neural_program.trainable_predicates,
                            key=lambda x: x.__str__()):
        print(predicate)

    print("\n\nIterable Constants: ({})"
          .format(len(neural_program.iterable_constants)))
    iterable_constants = set()
    for k, v in neural_program.iterable_constants.items():
        iterable_constants.add(v)
        print("{}:\t{}".format(k, v))

    other_constants = neural_program.constants - iterable_constants
    print("\n\nOther Constants: ({})"
          .format(len(other_constants)))
    for constant in other_constants:
        print(constant)

    print("\n\nExamples: ({})".format(
        sum(map(lambda x: len(x), neural_program.examples.values()))
    ))
    for predicate in sorted(neural_program.examples.keys(),
                            key=lambda x: x.__str__()):
        for fact in neural_program.examples[predicate].values():
            print(fact)

    father_matrix = neural_program.get_matrix_representation(Predicate(
        "father", 2))
    mother_matrix = neural_program.get_matrix_representation(Predicate(
        "mother", 2))

    # print("\nFather Matrix:")
    # print(father_matrix)
    # print("\nMother Matrix:")
    # print(mother_matrix)

    grand_father = father_matrix.dot(father_matrix) + \
                   father_matrix.dot(mother_matrix)

    print()
    for j, j in zip(*grand_father.nonzero()):
        print("{}::{}({}, {}).".format(grand_father[j, j],
                                       "grand_father",
                                       neural_program.iterable_constants[j],
                                       neural_program.iterable_constants[j]))

    # print("\n")
    # test = Predicate("test")
    # print("{}::{}.".format(neural_program.get_matrix_representation(test),
    #                        test.name))

    # print("\n")
    # male = Predicate("male", 1)
    # print(male)
    # representation = neural_program.get_matrix_representation(male)
    # for j, j in zip(*representation.nonzero()):
    #     print("{}::{}({}).".format(
    #         representation[j, j],
    #         "male",
    #         neural_program.iterable_constants[j]
    #     ))

    # print("\n")
    # age = Predicate("age", 2)
    # print(age)
    # age_weights, age_attributes = neural_program.get_matrix_representation(age)
    # for j, j in zip(*age_weights.nonzero()):
    #     print("{}::{}({}, {}).".format(
    #         age_weights[j, j],
    #         "age",
    #         neural_program.iterable_constants[j],
    #         age_attributes[j, j],
    #     ))

    # network = NeuralLogNetwork(neural_program)
    # paths, grounded_literals = find_clause_paths(targets["target"])
    # string_literals = ", ".join(map(lambda x: x.__str__(), grounded_literals))
    # rev_string_literals = ", ".join(
    #     reversed(list(map(lambda x: x.__str__(), grounded_literals))))
    #
    # print("Paths:")
    # for path in paths:
    #     print("Path:\t{}, {}\t<->\t{}, {}".format(
    #         path, string_literals, rev_string_literals, path.reverse()))

    x = np.zeros((2, len(neural_program.iterable_constants)))
    x[0, neural_program.index_for_constant(Constant("pierro"))] = 1.0
    # x[0, neural_program.index_for_constant(Constant("andrew"))] = 1.0
    x[1, neural_program.index_for_constant(Constant("maria"))] = 1.0

    log_dir = "/Users/Victor/Desktop/Experiments/NeuralLog"

    output = open(os.path.join(log_dir, "programs", "program.pl"), "w")
    print_neural_log_program(neural_program, output)
    output.close()

    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=os.path.join(log_dir, "board"), histogram_freq=1)
    # writer = tf.summary.create_file_writer(log_dir)
    # tf.summary.trace_on(graph=True, profiler=True)
    model = NeuralLogNetwork(neural_program)
    model.build_layers()
    # optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)
    optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)
    model.compile(loss="mse", optimizer=optimizer, metrics=["mse"])
    model.run_eagerly = True

    model.update_program()
    output = open(os.path.join(log_dir, "programs", "program2.pl"), "w")
    print_neural_log_program(neural_program, output)
    output.close()

    neural_dataset = NeuralLogDataset(model)
    features_1, labels_1 = neural_dataset.build(example_set="examples_1")
    # features_1 = tf.sparse.to_dense(features_1)
    # labels_1 = tuple(map(lambda x: tf.sparse.to_dense(x), labels_1))

    features_2, labels_2 = neural_dataset.build(example_set="examples_2")
    # features_2 = tf.sparse.to_dense(features_2)
    # labels_2 = tuple(map(lambda x: tf.sparse.to_dense(x), labels_2))

    dense_feature_1 = tf.one_hot(features_1, model.constant_size)
    dense_feature_2 = tf.one_hot(features_2, model.constant_size)
    predict(model, neural_program, dense_feature_1)
    predict(model, neural_program, dense_feature_2)
    epochs = 10
    verbose = 1
    # dataset = tf.data.Dataset.from_tensor_slices((features_1, labels_1))
    # dataset = dataset.map(DatasetMap(model.constant_size))
    dataset = neural_dataset.get_dataset("examples_1")
    dataset = dataset.batch(1)
    model.fit(dataset, epochs=epochs, callbacks=[tensorboard_callback],
              verbose=verbose)

    model.update_program()
    output = open(os.path.join(log_dir, "programs", "program3.pl"), "w")
    print_neural_log_program(neural_program, output)
    output.close()
    predict(model, neural_program, dense_feature_1)
    predict(model, neural_program, dense_feature_2)

    # dataset = tf.data.Dataset.from_tensor_slices((features_2, labels_2))
    # dataset = dataset.map(DatasetMap(model.constant_size))
    dataset = neural_dataset.get_dataset("examples_2")
    dataset = dataset.batch(1)
    model.fit(dataset, epochs=epochs, callbacks=[tensorboard_callback],
              verbose=verbose)

    model.update_program()
    output = open(os.path.join(log_dir, "programs", "program4.pl"), "w")
    print_neural_log_program(neural_program, output)
    output.close()
    predict(model, neural_program, dense_feature_1)
    predict(model, neural_program, dense_feature_2)

    logger.warning("Test")

    # neural_dataset = NeuralLogDataset(model)
    # features, labels = neural_dataset.build()
    # print(features, labels[0].indices, labels[0].values)


class DatasetMap:

    def __init__(self, constant_size):
        self.constant_size = constant_size

    def call(self, features, labels, *args, **kwargs):
        features = tf.one_hot(features, self.constant_size)
        labels = tuple(map(lambda x: tf.sparse.to_dense(x), labels))

        return features, labels

    __call__ = call

def predict(model, neural_program, x):
    """

    :param model: the model
    :type model: NeuralLogNetwork
    """
    predictions = model.predict(x)  # type: List[np.ndarray]
    predicates = list(model.predicates)
    x_numpy = x.numpy()
    print("*" * 10, "predictions", "*" * 10)
    for i in range(len(predicates)):
        for j in range(len(predictions[i])):
            indices = np.where(model.predict(x)[i][j] != 0.0)[0]
            if len(indices) == 0:
                continue
            term = neural_program.iterable_constants[np.argmax(x_numpy[j])]
            name = predicates[i][0].name
            if predicates[i][1]:
                name += "^{-1}"
            print(name, "(", term, ", X0):", sep="")
            for index in indices:
                print(predictions[i][j][index],
                      neural_program.iterable_constants[index], sep=":\t")
            print()
    print()


if __name__ == "__main__":
    main(sys.argv)
